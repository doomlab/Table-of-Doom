---
title             : "LAB: Linguistic Annotated Bibliography â€“ A searchable portal for normed database information"
shorttitle        : "Linguistic Bibliography"

author: 
  - name          : "Erin M. Buchanan"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "901 S. National Ave, Springfield, MO 65897"
    email         : "erinbuchanan@missouristate.edu"
  - name          : "Kathrene D. Valentine"
    affiliation   : "2"
  - name          : "Nicholas P. Maxwell"
    affiliation   : "1"

affiliation:
  - id            : "1"
    institution   : "Missouri State University"
  - id            : "2"
    institution   : "University of Missouri"

author_note: |
  Erin M. Buchanan is an Associate Professor of Quantitative Psychology at Missouri State University. K. D. Valentine is a Ph.D. candidate at the University of Missouri. Nicholas P. Maxwell is a Masters' candidate at Missouri State University. We thank Michael T. Carr, Farren E. Bankovich, Samantha D. Saxton, and Emmanuel Segui for their help with the original data processing, and William Padfield, Abigial Van Nuland, and Abbie Wikowsky for their help with the application develop for the website. 
  
abstract: |
  In the era of big data, psycholinguistic research is flourishing with numerous publications that advance our knowledge of concept characteristics and ways to study them. This article presents the Linguistic Annotated Bibliography (LAB) as a searchable web portal to quickly and easily access reliable database norms, related programs, and variable calculations. These publications (*N* = 706) were coded by language, number of stimuli, stimuli type (i.e., words, pictures, symbols), keywords (i.e., frequency, semantics, valence), and other useful information. This tool not only allows researchers to search for the specific type of stimuli needed for experiments, but also permits the exploration of publication trends across 100 years of research. Details about the portal creation and use are outlined, as well as various analyses of change in publication rates and keywords. In general, advances in computation power have allowed for the increase in dataset size in the recent decades, in addition to an increase in the number of linguistic variables provided in each publication.
  
keywords          : "database, stimuli, online portal, megastudy, trends"

bibliography      : ["lab.bib", "r-references.bib"]

figsintext        : no
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : yes
mask              : no

lang              : "english"
class             : "man"
output            : papaja::apa6_pdf
replace_ampersands: yes
csl               : apa6.csl
---

```{r load_packages, include = FALSE}
library("papaja")
library(shiny) #to cite shiny
library(reshape)
library(MOTE)
library(ggplot2)
library(cowplot)

#load the data
master = read.csv("lab_table.csv")

cleanup = theme(panel.grid.major = element_blank(), 
                panel.grid.minor = element_blank(), 
                panel.background = element_blank(), 
                axis.line.x = element_line(color = "black"),
                axis.line.y = element_line(color = "black"),
                legend.key = element_rect(fill = "white"),
                text = element_text(size = 15))
```

The advance of computational ability and the Internet have propelled research into an era of "big data" that has interesting implications for the field of psycholinguistics, as well as other experimental areas that use normed stimuli for their research. Traditionally, stimuli used for experimental psycholinguistics research were first normed through small in-house pilot studies, which were then used in many subsequent projects. While economic, this selection procedure's results could be potentially misleading as a factor of the stimuli, rather than experimental manipulation. Small individual lab norming projects may be tied to a lack of funding, time, computational power, or even interest in studying phenomena at the stimuli level. Now, we have the capability to collect, analyze, and publish large datasets for research into memory models [@Cree1999; @Moss2002; @Rogers2004; @Vigliocco2004], aphasias [@Vinson2003], probability and linguistics [@Cree2003; @McRae1997; @Pexman2003], valence [@Dodds2011; @Vo2009; @Warriner2013], and reading speeds and priming [@Balota2007; @Cohen-Shikora2013; @Hutchison2013; @Keuleers2012] to name a small subset of research avenues.

Big data has manifested in psycholinguistics over the last decade in the form of grant funded megastudies to collect and analyze large text corpora (i.e., the SUBTLEX projects) or to examine numerous word properties in one study (i.e., the Lexicon projects). The SUBTLEX projects were designed to analyze frequency counts for concepts across extremely large corpora sizes using subtitles as a substitute for natural speech. The investigation of these measures was first spurred by the realization that word frequency is an important predictor of naming and lexical decision times [@Balota2004; @Rayner1986]. While previous measures of frequency [i.e., @Baayen; @Burgess1998; @Kucera1967] were based on large one million+ word corpora, they were poor predictors of response latencies [@Balota2004; @Brysbaert2009; @Zevin2002]. Further, it appears from @Brysbaert2009's investigation into corpora size and type, that not only should the corpora be large (>sixteen million), but the underlying source of the text data matters (Internet versus subtitles), as well as the contextual diversity of the data [i.e., number of occurrences across sources; @Adelman2006]. Not only has @Brysbaert2009's work been included in newer lexical studies [@Hutchison2013; @Yap2011], but SUBTLEX projects have been published in Dutch [@Keuleers2010], Greek [@Dimitropoulou2010], Spanish [@Cuetos2011], Chinese [@Cai2010], French [@New2007], British English [@VanHeuven2014], and German [@Brysbaert2011].

The Lexicon projects involved creating large databases of validated mono- and multisyllabic words to assist in the creation of controlled experimental stimuli sets for future experiments. These databases contain lexical decision and naming response latencies, as well as typical word confound variables such as orthographic neighborhood, phonological, and morphological characteristics. While the English Lexicon Project [@Balota2007] is the most cited of the lexicons, other languages include Chinese [@Sze2014], Malay [@Yap2010], Dutch [@Keuleers2010], and British English [@Keuleers2012]. Another twenty or so similar lexical database publications can be found in the literature covering French [@Lete2004], Italian [@Barca2002], Arabic [@Boudelaa2010], and Portuguese [@Soares2014]. 

The availability of big data has augmented the psycholinguistic literature, but these projects are certainly time consuming due to the amount of participant data required to achieve reliable and stable norms. A solution to large data collection lies in several avenues of easily obtainable data. First, Amazon's Mechanical Turk, an online crowd sourcing avenue that allows researchers to pay users to complete questionnaires, has shown to be a reliable, diverse participant pool made available at very low cost [@Buhrmester2011; @Mason2012]. Researchers can pre-screen for specific populations, as well as post-screen surveys for incomplete or inappropriate responses [@Buchanan2018], thus saving time and money with the elimination of poor data. Because of the popularity of Mechanical Turk, large amounts of data can be collected in shorter time periods than traditional experiments. Mechanical Turk has been used to collect data for semantic word pair norms [@Buchanan2013], age of acquisition ratings [@Kuperman2012], concreteness ratings [@Brysbaert2013], past tense information [@Cohen-Shikora2013], and valence and arousal ratings [@Dodds2011; @Jasmin2012; @Warriner2013]. Additionally, in a similar vein to the SUBTLEX projects, linguistic data has been mined from open source data, such as the New York Times, music lyrics, and Twitter [@Dodds2011; @Kloumann2012]. Finally, @DeDeyne2013 have seen success in simply setting up a special website (www.smallworldofwords.com) to gamify the collection of word pair association norms.

The evolution of big data provides exciting opportunities for exploration into psycholinguistics, and this article features the trends in publications of normed datasets across the literature, allowing for a large-scale picture of the developments of trends in psychological stimuli. Historically, these norms have been published in journals connected to the Psychonomic Society, such as Behavior Research Methods, Psychonomic Monograph Supplements, and Perception and Psychophysics. The society once hosted an electronic database that contained the links to these norms, as well as a search tool to find information about previously published works [@Vaughan2004]. The sale of the society journals to Springer publications has improved journal visibility and user-friendly access, but also has left a need for an indexed list of database publications that span multiple keywords and journal websites. Therefore, the purpose of this article is twofold: 1) to present a searchable, cataloged database of normed stimuli and related materials for a wide range of experimental research, and 2) to examine trends in the publications of these articles to assess the big data movement within cogntive psychology.

# Website

This manuscript was written with *R* markdown and @R-papaja and can be found at https://osf.io/9bcws/. Readers can find the website by going to http://www.wordnorms.com, and the source files for the website can be found at https://github.com/doomlab/wordnorms. From the webpage, the top navigation bar includes a link to direct the reader to the LAB page. On the LAB page, we have included a purpose statement and several summary options. First, the variable tables include summary descriptions about the stimuli and keyword (tags) variables in this study. The links redirect to Shiny applications. Shiny is an open source graphical user interface *R* package that allows researchers to build interactive web applications [@R-shiny]. These apps connect to the LAB database and display the current *N*, minimum, maximum, mean and standard deviation for each variable, when appropriate. The advantage to using Shiny apps is dynamic updating of the database, so as new information is added, the app will display the most current statistics. Viewers can suggest articles that should be included in the dataset by using the email link included on the website. The entire dataset can be viewed and filtered based on keyword, language, and stimuli type. This search app allows for multiple filter options, so a person may drill down into very specific search criteria. Underneath the search functions, yearly trend visualization and descriptive statistics may be found including frequency tables of stimuli and keywords. Finally, the complete database in csv format can be downloaded. Specific features will be outlined below in relation to the database creation.

# Database Methods

## Materials

@Bradshaw1984 and @Proctor1999's lists of database information were used as starting points for collection of research articles. We searched *Academic Search Premier, PsycInfo, and ERIC* through the EBSCO host system, as well as *Google Scholar and PLoS One* to find other relevant articles using the following keywords: *corpus, linguistic database, linguistic norms, norms, and database*. Additionally, since many of the original articles were hosted by the Psychonomic Society, the Springer website was searched with these terms that covered the newer editions of *Behavior Research Methods* and *Memory & Cognition*. We then filtered for articles that met the following criteria: 1) contained database information as supplemental material, 2) demonstrated programs related to building research stimuli using normed databases, or 3) generated new calculations of lexical variables. Research articles that used normed databases in experimental design or tested those variables validity/reliability were excluded if they did not include new database information. Additional articles were found while coding initial publications by searching citations for stimuli selection. For example, the @Snodgrass1980 norms were cited in many newer articles on line drawings, and therefore this article was subsequently entered into the database. At the time of writing, 706 articles, books, websites, and technical reports were included in the following analyses.

## Coding Procedure

The tables with summaries from @Bradshaw1984 and @Proctor1999 were consulting for a starting point for data coding. Next, the first round of articles found (approximately 100) were analyzed to determine information that would be pertinent to a user who wished to search for normed stimuli. Based on these reviews and lab discussions, we coded the following information from each article: 1) journal information, 2) stimuli types, 3) stimuli language, 4) programs or corpus name, 5) keywords, which we refer to as tags, 6) special populations, and 7) other notes that did not fit into those categories. Each piece of information is detailed below. In some instances, codes were not used as frequently as expected based on these initial discussions, but were included to allow more specificity in searching, as well as the flexibility to include those options for articles subsequently added to the database.

### Journal Information

Each article was coded with the citation information, and a complete list of citations can be found on the website portal by clicking on view and search data. All author last names are listed, along with publication year, article title, journal title, volume, page numbers, and digital object identifier (DOI) when available. This information is listed in citation format in the Shiny app and separated into columns in the downloadable data for easier sorting and searching. For newer articles that have been published online first without volume or page numbers, X and XX-XX are used as placeholders until official publication. Although APA style dictates et al. for references after the second author or immediately for large author publications, all names were included each time they were referenced (see below). The inclusion of these names allows a user to search for specific researchers, as well as separates different publications by the same first author. A complete list of publication sources, number of times cited, and percentages can be found online by using the frequency statistics link.  

### Stimuli Types

While this publication was originally intended for traditional linguistic database norms, other types of experimental stimuli used in concept studies were apparent after background review. Therefore, stimuli were coded based on the dominant description from the article (i.e., although heteronyms are words and word pairs, they were coded specifically as heteronyms). The number of stimuli presented in the appendix or database was coded with the stimuli, unless the article covered specific programs, search or experimental creation tools, which is the majority of the "other" stimuli category. Because many articles included two types of stimuli, or references to different articles where stimuli were selected from, two options for stimuli were included. Therefore, the total values for number of stimuli do not add up to the number of articles in the database because of multiple instances in articles or no stimuli for program descriptions. Table \@ref(tab:stim-table) includes a stimuli list, the number of times that each stimuli was used, percentage of the total stimuli codes, the mean and standard deviation of the number of those stimuli, minimum/maximum values, and a brief variable description. Researchers often cited specific previous works where stimuli were selected from, and these references were included, which can be found in the downloaded data. Table \@ref(tab:stim-table) is included dynamically online under view the variable table and view the frequency table.

```{r stim-table, echo = FALSE, results = 'asis'}
#pull the descriptions
stimwordtable = read.csv("StimWordTab.csv")

#use just the stim columns
type1 = master[ , c("no1", "type1")]
type2 = master[ , c("no2", "type2")]
colnames(type2) = c("no1", "type1")
stimworddata = rbind(type1, type2)
stimworddata = subset(stimworddata, type1 != "")
stimworddata$type1 = droplevels(stimworddata$type1)
stimworddata$type1 = factor(stimworddata$type1, 
                            levels = stimwordtable$Stimuli)

stimwordtable$N = table(stimworddata$type1)

stimwordtable$Minimum = apa(tapply(stimworddata$no1, stimworddata$type1, min, na.rm = T),2)
stimwordtable$Maximum = apa(tapply(stimworddata$no1, stimworddata$type1, max, na.rm = T),2)
stimwordtable$M = apa(tapply(stimworddata$no1, stimworddata$type1, mean, na.rm = T),2)
stimwordtable$SD = apa(tapply(stimworddata$no1, stimworddata$type1, sd, na.rm = T),2)
stimwordtable$Percent = apa(table(stimworddata$type1)/sum(table(stimworddata$type1))*100,1)

stimwordtable[ , c("Stimuli","Description","N","Percent",
                   "Minimum","Maximum","M","SD")]
apa_table(stimwordtable,
          align = c("l", "l", rep("c", 6)), 
          caption = "Stimuli Definitions and Descriptive Statistics")
```

### Stimuli Language

The language of the stimuli set was coded by starting with the most common languages from the first articles surveyed, and others were added as it was apparent that several norms were present for that language (such as Japanese, Dutch, and Greek). If the stimuli were non-linguistic  selections, like pictures and line drawings, the language of the participants used to norm the set was used, which was commonly English. The other category was used for low-frequency languages, as well as a multiple category for datasets with more than one set of language norms. One potential limitation of the LAB was that English is the first language for the authors; however, translation tools were used to code sources found in other languages. Table \@ref(tab:lang-table) indicates language frequencies and percentages, and the online version can be found by clicking the view frequency statistics link.

```{r lang-table, echo = FALSE, results = 'asis'}
langtable = as.data.frame(table(master$language))

colnames(langtable) = c("Language", "N")
langtable$Percent = apa(table(master$language)/sum(table(master$language))*100,1)

apa_table(langtable,
          align = c("l", rep("c", 2)), 
          caption = "Language Descriptive Statistics")
```

### Program/corpus name

In many instances, megastudies are often named, such as the English Lexicon Project [@Balota2007], for easier reference. This information was included in the in the dataset, which will also help researchers with the stimuli references as described above. For example, a newer study may reference using the BOSS database [@Brodeur2010] and having that information would make searching for the original article easier by using the corpus name column (especially in instances the dataset name is not listed in the article title). The names of programs or tools were also entered, such as NIM [@Guasch2013], a newer stimuli selection tool for psycholinguistic studies.

### Keyword Tags

Keyword tags are the majority of the database, as they allow for the best understanding of trends and availability of stimuli. Table \@ref(tab:lang-table) portrays a list of tags, frequencies, percentages, descriptions, and correlations (described below). Each article was coded with tags based on the description of the accessible data, and one article may have many tags. However, due to the cumulative nature of database research, this tagging system does not mean that each article collected that particular type of data. The most common example of this distinction occurs when data was combined across sources, but presented in a new article. The @Maki2004 semantic distance norms also included values from the South Florida Free Association norms [@Nelson2004], and Latent Semantic Analysis [@Landauer1997]. Therefore, this article was coded with association and semantics, even though the association norms were not collected in that paper. As described above, some small frequency tags were used because of the initial pass through newer articles, but these were left in the database because of their specificity, and they can be used in future additions.

```{r tag-table, echo = FALSE, results = 'asis'}
tagwordtable = read.csv("TagWordTab.csv")
tagworddata = master[ , c("aoa","ambiguity","arousal","assoc","category",
                               "cloze","complex","concrete","confusion","dist",
                               "dominate","easelearn","familiar","freq","gpc",
                               "identify","identifyld","identifyn","imageagree",
                               "imagevar", "imagine","intense","letters", "meaning",
                               "modality","morph","nameagree","orthon","pos",
                               "phonemes","phonon","prime","pronounce",
                               "rt","recall","recognition","rime","semantic",
                               "sensory","sentcomp","similar","syllables",
                               "typical","valence","visualcomp","wordcomp","year")]

longtag = melt(tagworddata,
                   id = c("year"),
                   measured = c("aoa","ambiguity","arousal","assoc","category",
                                "cloze","complex","concrete","confusion","dist",
                                "dominate","easelearn","familiar","freq","gpc",
                                "identify","identifyld","identifyn","imagevar",
                                "imagine","intense","meaning","modality","morph",
                                "nameagree","orthon","pos","phonon","prime","pronounce",
                                "rt","recall","recognition","rime","semantic",
                                "sensory","sentcomp","typical","valence","visualcomp",
                                "wordcomp","syllables","letters","phonemes","imageagree",
                                "similar"))
longtag$year = as.numeric(as.character(longtag$year))
tagwordtable$r = apa(as.matrix(by(longtag, longtag$variable, function(x) {cor(x$year, x$value, use = "pairwise.complete.obs")}))[ , 1],3, F)
tagwordtable$r[tagwordtable$N < 30] = NA
tagwordtable$N = table(longtag$variable[longtag$value == 1])
tagwordtable$Percent = apa(table(longtag$variable[longtag$value == 1])/sum(table(longtag$variable[longtag$value == 1]))*100, 1)

tagwordtable = tagwordtable[ , c("Stimuli", "Description", "N", "Percent", "r")]

apa_table(tagwordtable,
          align = c("l", "l", rep("c", 3), 
          caption = "Tag Definitions and Descriptive Statistics"))
```

### Special Populations

While coding articles, it became apparent that a subset of the normed data was tested on specific special populations. Consequently, demographic data such as gender, age, ethnicity, and grade school year were listed as described in the article (i.e., if ages were used, age was listed, but if grade year was used, it was listed rather than translating to specific ages).

### Other/Notes

Lastly, places for more description were included for tags or variables not frequently used, which was especially useful for program descriptions, as well as descriptions of specific types of stimuli (i.e., CVC trigrams). In several instances, notes that appeared frequently were moved to tags (such as similarity) after the database had several hundred articles sampled. All information described above without a specific table (special populations, other, program/corpus names, and journal information) can be found by downloading the complete dataset.

# Results and Discussion

## Journals

```{r journal, include=FALSE}
brm_tot = apa(length(grep("Behavior Research Methods", master$ref_journal))/nrow(master)*100,1)
psych_mono = apa(length(grep("Psychonomic Monograph Supplements", master$ref_journal))/nrow(master)*100,1)
vlvb = apa(length(grep("Journal of Verbal Learning", master$ref_journal))/nrow(master)*100,1)
psych_science = apa(length(grep("Psychonomic Science", master$ref_journal))/nrow(master)*100,1)
jep = apa(length(grep("Journal of Experimental", master$ref_journal))/nrow(master)*100,1)
pandp = apa(length(grep("Perception &", master$ref_journal))/nrow(master)*100,1)
jep = apa(length(grep("Journal of Experimental", master$ref_journal))/nrow(master)*100,1)
memory = apa(length(grep("Memory & Cognition", master$ref_journal))/nrow(master)*100,1)
bullet = apa(length(grep("Psychonomic Society", master$ref_journal))/nrow(master)*100,1)
norms = apa(length(grep("Norms of", master$ref_journal))/nrow(master)*100,1)
```

Journal results, unsurprisingly, show that the wealth of data was published in *Behavior Research Methods* (`r brm_tot` combined across name changes). However, a large number of articles also appeared in *Psychonomic Monograph Supplements* (`r psych_mono`), *Journal of Verbal Learning and Verbal Behavior* (`r vlvb`), *Psychonomic Science* (`r psych_science`), *Journal of Experimental Psychology* (combined across subjournals, `r jep`), *Perception & Psychophysics* (`r pandp`), *Memory & Cognition* (`r memory`), *Bulletin of the Psychonomic Society* (`r bullet`), and *Norms of Word Association* [`r norms`; @Postman1970]. The complete list can be found in the frequency statistics online, as there were 129 different entries for journals, books, and websites of publications. While some of these sources were not published with peer review, they were generally found through citations of other peer-reviewed work. Although *Behavior Research Methods* has dominated the field for publications, the large array of options for publishing indicates a growth in the available avenues for researchers in this field (for example, open source journals such as *PLoS ONE* and websites). 

Figure \@ref(fig:pub-fig) portrays the number of publications across years, and there has been a clear expansion of database and program papers, as part of the growth in big data. Interestingly, a first growth of publications tracks with the 1950s cognitive revolution [@Miller2003], but an odd decline in publications occurred from the 1970s to 1990s. The last twenty years has shown unbelievable progress in this area, at over `r sum(as.numeric(na.omit(master$year >= 2010)))` publications since 2010 alone. This chart can be found in greater detail online, under the Papers Per Year link, showing the ups and downs of publications by year in a larger format with the ability to control year and bin width. For example, 2004, 2010, 2013-2015, and 2017 were big years for linguistic publications, each with 30 or more publications. Even with these fluctuations, a clear growth curve in publications can be found since the 90s.

```{r pub-fig, echo=FALSE, fig.cap="Publication frequency across years.", fig.height=6, fig.width=6}
yearhist = ggplot(master, aes(year))
    yearhist +
    geom_histogram(binwidth = 3, 
                   color = "black", 
                   fill = "white") +
    xlab("Year") + 
    ylab("Frequency") +
    cleanup +
      coord_cartesian(xlim = c(1900, 2025))
```

### Stimuli

Stimuli are presented in Table \@ref(tab:lang-table), and a review of this table indicated that the publication of word stimuli was slightly under half the dataset (`r stimwordtable$Percent[stimwordtable$Stimuli == "Words"]`), which has quite a large range of quantity of stimuli from only ten words to a large corpus of over 500 million words. The wide range of data includes these corpora materials, but there are very large word norming projects outside of the corpora included in the LAB. Other types of word stimuli also appear commonly in the LAB data such as categories, letters, and word pairs. Because linguistic data was of particular interest, we selected publications based on words and word pairs, and plotted the number of stimuli presented in the paper to examine big data trends. These data were broken down by set size in Figure \@ref(fig:word-fig). The upper left hand quadrant shows all stimuli across years, and the big data publications stand out in the last fifteen years of publications. This data was then further broken down into small datasets (<1,000 stimuli; upper right quadrant), medium datasets (1,000 - 1,000,000 stimuli; bottom left quadrant), and large datasets (1,000,000+ although there is a large jump between medium and large as most data is either half million or less or a million or more; bottom right quadrant). The small dataset graph shows that these publications are common across time, while the bottom two quadrants are more telling for the megastudies trend investigation. As with languages and tags (below), we see an increase in the number of medium and very large datasets across the years where the lone large dataset outlier in the early years is the Brown Corpus [@Kucera1967]. 

```{r word-fig, echo=FALSE, fig.cap="Number of word stimuli plotted across years. Top left quandrant includes all word stimuli. Top right quadrant includes word stimuli ranging up to 1000 words, bottom left quadrant portrays stimuli counts from 1000 to one million, and bottom right quadrant indicates all stimuli above one million.", fig.height=8, fig.width=8}

type1 = master[ , c("no1", "type1", "year")]
type2 = master[ , c("no2", "type2", "year")]
colnames(type2) = c("no1", "type1", "year")
stimworddata = rbind(type1, type2)
stimworddata = subset(stimworddata, type1 != "")
stimworddata$type1 = droplevels(stimworddata$type1)
stimworddata$type1 = factor(stimworddata$type1, 
                            levels = stimwordtable$Stimuli)

#all graph
stimword = subset(stimworddata, type1 == "Words" | type1 == "Word Pairs")
allword = ggplot(stimworddata, aes(year, no1)) + 
  geom_point() + 
  cleanup + 
  xlab("Publication Year") +
  ylab("Number of Stimuli")

#small graph
small = subset(stimword, no1 <= 1000)
smallword = ggplot(small, aes(year, no1)) + 
  geom_point() + 
  cleanup + 
  xlab("Publication Year") +
  ylab("Number of Stimuli") + 
  coord_cartesian(ylim = c(0, 1000), xlim = c(1900,2018)) +
  scale_x_continuous(breaks = c(1900, 1950, 2000))
  
#medium graph
med = subset(stimword, no1 > 1000 & no1 < 1000000)
medword = ggplot(med, aes(year, no1)) + 
  geom_point() + 
  cleanup + 
  xlab("Publication Year") +
  ylab("Number of Stimuli") + 
  coord_cartesian(ylim = c(1000, 600000), xlim = c(1900,2018)) +
  scale_y_continuous(breaks = c(1000,100000,200000,300000,400000,500000, 6000000),
                      labels = function(x) format(x, scientific = TRUE)) +
  scale_x_continuous(breaks = c(1900, 1950, 2000))

#large graph
large = subset(stimword, no1 >=1000000)
largeword = ggplot(large, aes(year, no1)) + 
  geom_point() + 
  cleanup + 
  xlab("Publication Year") +
  ylab("Number of Stimuli")  + 
  coord_cartesian(ylim = c(1000000, 600000000), xlim = c(1900,2018)) +
  scale_y_continuous(breaks = c(1000000,200000000,400000000,600000000),
                     labels = function(x) format(x, scientific = TRUE)) +
  scale_x_continuous(breaks = c(1900, 1950, 2000))

completegraph = plot_grid(allword, smallword, medword, largeword,
                   hjust = -1,
                   nrow = 2
)
completegraph
```

### Languages

```{r lang-analysis, include=FALSE}
noneng = subset(master, language != "English" & language != "British English")
```

The variety and number of languages for stimuli provided an encouraging picture of the growth and diversity of psycholinguistic stimuli, as seen in Table \@ref(tab:lang-table). Many articles include multiple languages (`r langtable$Percent[langtable$Language == "Multiple"]`), as well as the inclusion of both Portuguese (`r langtable$Percent[langtable$Language == "Portuguese"]`) and Spanish (`r langtable$Percent[langtable$Language == "Spanish"]`), French (`r langtable$Percent[langtable$Language == "French"]`), and German (`r langtable$Percent[langtable$Language == "German"]`). To examine trends, the English only articles were filtered out of the dataset since they were the majority of publications (`r langtable$Percent[langtable$Language == "English"]`) and were published across all years present in this data. Of the `r nrow(noneng)` non-English publications, `r sum(noneng$language == "Multiple")` included multiple langauges, and `r sum(noneng$language == "Multiple" & noneng$year > 2010)` of these were published after 2010. Additionally, the last ten years (2008 and later) have seen an explosion of publications in non-English languages, `r sum(noneng$year >= 2008, na.rm = T)`, with `r sum(noneng$year == 2017, na.rm = T)` in 2017 alone. 

### Tags

```{r tag-fig, echo=FALSE, fig.cap="Publication frequency across years.", fig.height=6, fig.width=6}
master$totaltag = apply(master[ , 22:67], 1, sum, na.rm = T)

taggraph = ggplot(master, aes(year, totaltag)) + 
  geom_point() + 
  cleanup + 
  xlab("Publication Year") +
  ylab("Number of Tags")

taggraph
```

Table \@ref(tab:tag-table) displays the number, percentages, correlations of tags across year, and descriptions of tags. Undoubtedly, these tags represent changes in terminology over time, and some could be combined or recoined. However, even if low frequency (*N* < 10; nine tags) tags were excluded, thirty-seven different tags were used to describe the types of psycholinguistic data. Many of these tags can be considered individual research areas, and the sizeable number of different options indicates how complex and diverse the field has become since the publication of free association norms in 1910 (@Kent & Rosanoff association norms).

The total number of tags for each publication was then tallied, and this data was plotted in Figure \@ref(tab:tag-fig) to visualize if the number of variables included in a study has grown over time (*M* = `r apa(mean(master$totaltag), 2)`, *SD* = `r apa(sd(master$totaltag),2)`). The correlation between total tags and year was `rapa_print(cor.test(master$totaltag, master$year, use = "pairwise.complete.obs"))$full_result`, indicating a small increase in total tags used over time. Even considering the larger number of publications in the 2000s versus 1950s to 1970s, it appeared that the number of keywords for articles was also slowly growing over time. This trend may indicate the evolution in computing possibilities to be able to publish large amounts of data, but also may indicate a desire to combine datasets so that even more stimuli may be considered at once for modeling or experiment creation.

Next, tags with at least a sample of 30 publications were investigated individually for trends across time (correlations presented in Table \@ref(tab:tag-table)). Individual histograms can be created by clicking on the Tags Per Year link online, which show the total frequency of the selected tag by year. Some small positive trends were found, such as the increase in arousal, age of acquisition, syllables, familiarity, and valence norms. Intriguingly, meaningfulness and association both showed negative correlations, but these correlations can be understood as an artifact of the publication of a book on association norms in the 1970s [@Postman1970], as well as a recent drop off of in the small but steady use of meaningfulness. These small correlations may partially be explained by the sheer number and variation of data available in the LAB portal, as one would expect the number of frequency tags to increase with the recent SUBTLEX publications. Indeed, if the frequency tags were plotted by year an increase across the last decade (16 in 2010 and 2013, and 21 in 2014) can be found. Readers are encouraged to view the individual graphs for tags to investigate the change of keyword publication over time, including the rise and demise of several research areas. For example, confusion matrices heyday appeared to range from the early 70s to the mid 80s, while arousal norms do not make a consistent appearance until the late 90s. 

# Conclusion

This article had two main purposes: 1) to present the LAB dataset and portal as an annotated bibliography and searchable tool for researchers, and 2) to view trends in psycholinguistic research with an eye toward big data. We believe the LAB website will be a useful channel for all levels of researchers, from graduate students looking for experimental stimuli to design their experiments, to the familiar investigator who wishes to dig deeper into the diverse choices offered. Further, while the majority of publications occur in one particular journal, the LAB allows someone to find articles they may have missed in other areas with the advantage of being collected into one location. User-friendly search tools are provided to aide in searching for specific languages, stimuli, or keywords, as well as multiple outputs for easy copying into Excel or SPSS. While this article's statistics will become dated with the updates to the LAB, dynamic tables and graphs are provided online to see the current status of the field. Lastly, we encourage users to actively report errors and suggest updates for the LAB dataset as a way to crowd source information that is surely missing, especially in non-English languages.

In the introduction, we provided two examples of current megastudies (SUBTLEX and the Lexicon projects), in addition to how researchers might collect big data through Mechanical Turk or Twitter. This article stepped back from looking at individual, large studies or ways to collect data to use the information provided by publications as a window into the fluctuations of the field. Megastudies have become a prevalent topic, but data could have revealed that this popularity was due to recent publication of a small subset of articles. Instead, analyses showed that not only are the numbers of publications accumulating, but the sizes of datasets are also growing in tandem. Megastudies specifically focus on large datasets, but big data can also be indicated here by the divergence in languages available, number of places to publish such data, and the increasing number of keywords for articles across years. Time will tell if these trends can and will continue or if certain areas will see a confusion matrix type decline after many large datasets are published. With the move of traditional lab experiments to smartphone and tablet technology [@Dufau2011], it seems likely that researchers in psycholinguistics will continue to find new and creative ways to modernize the field.

\newpage

# References
```{r create_r-references}
r_refs(file = "r-references.bib")
```

\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}
